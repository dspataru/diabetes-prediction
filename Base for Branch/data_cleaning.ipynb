{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5e9838",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d0cad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n",
      "C:\\Users\\daian\\AppData\\Local\\Temp\\ipykernel_17904\\721025697.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data = pd.read_sas(\"LLCP2022.xpt\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_sas(\"LLCP2022.xpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f884180d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENM1</th>\n",
       "      <th>...</th>\n",
       "      <th>_SMOKGRP</th>\n",
       "      <th>_LCSREC</th>\n",
       "      <th>DRNKANY6</th>\n",
       "      <th>DROCDY4_</th>\n",
       "      <th>_RFBING6</th>\n",
       "      <th>_DRNKWK2</th>\n",
       "      <th>_RFDRHV8</th>\n",
       "      <th>_FLSHOT7</th>\n",
       "      <th>_PNEUMO3</th>\n",
       "      <th>_AIDTST4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02032022'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'03'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>b'2022000001'</td>\n",
       "      <td>2.022000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02042022'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'04'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>b'2022000002'</td>\n",
       "      <td>2.022000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02022022'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>b'2022000003'</td>\n",
       "      <td>2.022000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02032022'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'03'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>b'2022000004'</td>\n",
       "      <td>2.022000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02022022'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>b'2022000005'</td>\n",
       "      <td>2.022000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.400000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE  \\\n",
       "0     1.0     1.0  b'02032022'  b'02'  b'03'  b'2022'    1100.0   \n",
       "1     1.0     1.0  b'02042022'  b'02'  b'04'  b'2022'    1100.0   \n",
       "2     1.0     1.0  b'02022022'  b'02'  b'02'  b'2022'    1100.0   \n",
       "3     1.0     1.0  b'02032022'  b'02'  b'03'  b'2022'    1100.0   \n",
       "4     1.0     1.0  b'02022022'  b'02'  b'02'  b'2022'    1100.0   \n",
       "\n",
       "           SEQNO          _PSU  CTELENM1  ...  _SMOKGRP  _LCSREC  DRNKANY6  \\\n",
       "0  b'2022000001'  2.022000e+09       1.0  ...       4.0      NaN       2.0   \n",
       "1  b'2022000002'  2.022000e+09       1.0  ...       4.0      NaN       2.0   \n",
       "2  b'2022000003'  2.022000e+09       1.0  ...       4.0      NaN       2.0   \n",
       "3  b'2022000004'  2.022000e+09       1.0  ...       3.0      2.0       2.0   \n",
       "4  b'2022000005'  2.022000e+09       1.0  ...       4.0      NaN       1.0   \n",
       "\n",
       "       DROCDY4_  _RFBING6      _DRNKWK2  _RFDRHV8  _FLSHOT7  _PNEUMO3  \\\n",
       "0  5.397605e-79       1.0  5.397605e-79       1.0       1.0       2.0   \n",
       "1  5.397605e-79       1.0  5.397605e-79       1.0       2.0       2.0   \n",
       "2  5.397605e-79       1.0  5.397605e-79       1.0       NaN       NaN   \n",
       "3  5.397605e-79       1.0  5.397605e-79       1.0       9.0       9.0   \n",
       "4  1.000000e+01       1.0  1.400000e+02       1.0       NaN       NaN   \n",
       "\n",
       "   _AIDTST4  \n",
       "0       2.0  \n",
       "1       2.0  \n",
       "2       2.0  \n",
       "3       2.0  \n",
       "4       2.0  \n",
       "\n",
       "[5 rows x 326 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the Dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd41e1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445132, 326)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dimension of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655a0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting a few specific coloumns from the main dataset - 34 columns\n",
    "imp_df = data [[\"_STATE\", \"SEXVAR\", \"_INCOMG1\", \"HEIGHT3\", \"HTIN4\", \"HTM4\", \"WTKG3\", \"_BMI5CAT\", \"_RACE1\", \"_AGEG5YR\", \"DIABETE4\", \"PREDIAB2\",\n",
    "                \"PHYSHLTH\", \"MENTHLTH\", \"DIABTYPE\", \"_TOTINDA\", \"POORHLTH\", \"EXERANY2\",  \"SLEPTIM1\", \"DISPCODE\",\n",
    "                \"PRIMINSR\", \"PERSDOC3\", \"CHECKUP1\", \"PDIABTS1\", \"INSULIN1\", \"CHKHEMO3\", \"EYEEXAM1\", \"DIABEYE1\", \"DIABEDU1\" , \"FEETSORE\",  \n",
    "                \"CVDINFR4\", \"CVDCRHD4\", \"CVDSTRK3\", \"HAVARTH4\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d0e843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445132, 34)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dimension of the data\n",
    "imp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26422a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping only the values with completed interview (dropped around 91,861 values)\n",
    "imp_df = imp_df[(imp_df['DISPCODE'] == 1100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df99a11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353271, 34)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dimension of the data\n",
    "imp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d901ab6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_STATE           0\n",
       "SEXVAR           0\n",
       "_INCOMG1         0\n",
       "HEIGHT3          1\n",
       "HTIN4        10766\n",
       "HTM4          7867\n",
       "WTKG3        18784\n",
       "_BMI5CAT     23406\n",
       "_RACE1           1\n",
       "_AGEG5YR         0\n",
       "DIABETE4         0\n",
       "PREDIAB2    234016\n",
       "PHYSHLTH         1\n",
       "MENTHLTH         0\n",
       "DIABTYPE    342495\n",
       "_TOTINDA         0\n",
       "POORHLTH    149151\n",
       "EXERANY2         0\n",
       "SLEPTIM1         0\n",
       "DISPCODE         0\n",
       "PRIMINSR         1\n",
       "PERSDOC3         0\n",
       "CHECKUP1         1\n",
       "PDIABTS1    234018\n",
       "INSULIN1    342495\n",
       "CHKHEMO3    342495\n",
       "EYEEXAM1    342495\n",
       "DIABEYE1    342495\n",
       "DIABEDU1    342495\n",
       "FEETSORE    342495\n",
       "CVDINFR4         1\n",
       "CVDCRHD4         0\n",
       "CVDSTRK3         0\n",
       "HAVARTH4         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the count of null values in each column\n",
    "imp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2637c",
   "metadata": {},
   "source": [
    "After checking the count of Null values for each colums, we realised that the a few columns have question specific to the patients who have diabetes therefore they all have same number of missing values (questions that were not asked from the non-diabetic people). Therefore, a separate dataframe was created for these columns and these columns were dropped and a new dataframe \"gen_info_df\" was created without these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f78960f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353271, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a separate df with columns containg values for data-specifc to people having diabetes\n",
    "diabetes_df = imp_df[[\"DIABETE4\", \"DIABTYPE\", \"PREDIAB2\", \"PDIABTS1\", \"INSULIN1\", \"CHKHEMO3\", \"EYEEXAM1\", \"DIABEYE1\", \"DIABEDU1\", \"FEETSORE\"]] \n",
    "\n",
    "diabetes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f7bdc01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353271, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing columns specific to the people who have diabetes and creating a new dataframe with all the general info\n",
    "# Dropping 9 columns-specifc to diabetes\n",
    "gen_info_df= imp_df.drop(columns = [\"DIABTYPE\", \"PREDIAB2\", \"PDIABTS1\", \"INSULIN1\", \"CHKHEMO3\", \"EYEEXAM1\", \n",
    "                                    \"DIABEYE1\", \"DIABEDU1\", \"FEETSORE\"]).copy()\n",
    "gen_info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4df37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>DIABTYPE</th>\n",
       "      <th>PREDIAB2</th>\n",
       "      <th>PDIABTS1</th>\n",
       "      <th>INSULIN1</th>\n",
       "      <th>CHKHEMO3</th>\n",
       "      <th>EYEEXAM1</th>\n",
       "      <th>DIABEYE1</th>\n",
       "      <th>DIABEDU1</th>\n",
       "      <th>FEETSORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445127</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445128</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445129</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445130</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445131</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353271 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DIABETE4  DIABTYPE  PREDIAB2  PDIABTS1  INSULIN1  CHKHEMO3  EYEEXAM1  \\\n",
       "0            1.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            3.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            3.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3            3.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4            3.0       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "445127       3.0       NaN       3.0       7.0       NaN       NaN       NaN   \n",
       "445128       3.0       NaN       3.0       1.0       NaN       NaN       NaN   \n",
       "445129       3.0       NaN       3.0       7.0       NaN       NaN       NaN   \n",
       "445130       3.0       NaN       1.0       1.0       NaN       NaN       NaN   \n",
       "445131       3.0       NaN       3.0       1.0       NaN       NaN       NaN   \n",
       "\n",
       "        DIABEYE1  DIABEDU1  FEETSORE  \n",
       "0            NaN       NaN       NaN  \n",
       "1            NaN       NaN       NaN  \n",
       "2            NaN       NaN       NaN  \n",
       "3            NaN       NaN       NaN  \n",
       "4            NaN       NaN       NaN  \n",
       "...          ...       ...       ...  \n",
       "445127       NaN       NaN       NaN  \n",
       "445128       NaN       NaN       NaN  \n",
       "445129       NaN       NaN       NaN  \n",
       "445130       NaN       NaN       NaN  \n",
       "445131       NaN       NaN       NaN  \n",
       "\n",
       "[353271 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76e2ab2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_STATE           0\n",
       "SEXVAR           0\n",
       "_INCOMG1         0\n",
       "HEIGHT3          1\n",
       "HTIN4        10766\n",
       "HTM4          7867\n",
       "WTKG3        18784\n",
       "_BMI5CAT     23406\n",
       "_RACE1           1\n",
       "_AGEG5YR         0\n",
       "DIABETE4         0\n",
       "PHYSHLTH         1\n",
       "MENTHLTH         0\n",
       "_TOTINDA         0\n",
       "POORHLTH    149151\n",
       "EXERANY2         0\n",
       "SLEPTIM1         0\n",
       "DISPCODE         0\n",
       "PRIMINSR         1\n",
       "PERSDOC3         0\n",
       "CHECKUP1         1\n",
       "CVDINFR4         1\n",
       "CVDCRHD4         0\n",
       "CVDSTRK3         0\n",
       "HAVARTH4         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the null values for each column\n",
    "gen_info_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75004d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'POORHLTH' represents \"Number of days you had poor physical or mental health\" that information is laready present in \n",
    "#\"PHYSHLTH\" and \"MENTHLTH\" therefore 'POORHLTH' was dropped \n",
    "gen_info_df= gen_info_df.drop(columns = [\"POORHLTH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "766ee6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_STATE : [ 1.  2.  4.  5.  6.  8.  9. 10. 11. 12. 13. 15. 16. 17. 18. 19. 20. 21.\n",
      " 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39.\n",
      " 40. 41. 42. 44. 45. 46. 47. 48. 49. 50. 51. 53. 54. 55. 56. 66. 72. 78.]\n",
      "SEXVAR : [2. 1.]\n",
      "_INCOMG1 : [9. 3. 6. 5. 4. 1. 7. 2.]\n",
      "HEIGHT3 : [9999.  503.  502.  505.  511.  504.  507.  506.  508.  501.  604.  602.\n",
      "  510.  601.  509.  500.  600.  605. 7777.  411.  409.  603.  408.  410.\n",
      "  400.  606.  608.  607.  403.  407.  405. 9165.  611. 9175. 9183. 9180.\n",
      "  701.  705.  300.  309. 9152. 9170. 9174. 9151. 9153. 9184. 9190. 9160.\n",
      " 9154. 9172. 9187. 9157. 9163. 9161. 9149. 9169. 9178. 9156. 9140. 9150.\n",
      " 9167. 9155. 9164. 9158. 9162. 9179. 9168. 9145. 9146. 9189.  406.  700.\n",
      "  609.  303.  404. 9173. 9166. 9177. 9195. 9171. 9186. 9182. 9185.  311.\n",
      " 9130.  610. 9148.  702. 9176. 9118. 9159. 9181. 9105. 9138. 9147.  703.\n",
      "  402. 9120. 9117. 9193.  401. 9144.  306. 9198. 9104. 9090. 9135.  305.\n",
      " 9143.  210.  800. 9192. 9110.  704. 9205.  308. 9103.  708. 9125.  801.\n",
      "   nan  302. 9106. 9142. 9115.  706. 9109.  307. 9196.  711. 9127. 9207.\n",
      " 9100. 9188.  310. 9108. 9114. 9102.  304.  209. 9254. 9200. 9202. 9194.\n",
      " 9095.  200.]\n",
      "HTIN4 : [nan 63. 62. 65. 71. 64. 67. 66. 68. 61. 76. 74. 70. 73. 69. 60. 72. 77.\n",
      " 59. 57. 75. 56. 58. 48. 78. 80. 79. 51. 55. 53. 83. 85. 89. 36. 45. 54.\n",
      " 84. 81. 39. 52. 47. 82. 86. 87. 50. 49. 42. 41. 88. 44. 92. 38. 90. 43.\n",
      " 95. 46. 40.]\n",
      "HTM4 : [ nan 160. 157. 165. 180. 163. 170. 168. 173. 155. 193. 188. 178. 185.\n",
      " 175. 152. 183. 196. 150. 145. 191. 142. 147. 122. 198. 203. 201. 130.\n",
      " 140. 135. 211. 216. 226.  91. 114. 174. 151. 153. 184. 190. 154. 172.\n",
      " 187. 161. 149. 169. 156. 167. 164. 158. 162. 179. 146. 189. 137. 213.\n",
      " 206.  99. 132. 166. 177. 195. 171. 186. 182. 119. 208. 148. 218. 176.\n",
      " 118. 159. 181. 105. 138. 221. 127. 120. 117. 124. 144. 107. 104. 143.\n",
      " 192. 110. 224. 205. 112. 103. 234. 125.  97. 106. 115. 229. 109. 241.\n",
      " 207. 100. 108. 102. 200. 202. 194.  95.]\n",
      "WTKG3 : [   nan  6804.  6350.  5398.  8482.  6260.  7348.  8165.  7484.  5942.\n",
      "  8528. 10659.  7121.  6441.  6123.  9072.  6577.  8029.  8618. 10705.\n",
      "  5715. 10523.  7711.  5670.  7938. 11340. 10206.  5987. 10433.  5352.\n",
      "  6169. 13608.  3447.  9979. 12701.  7893.  5897.  9208.  7257.  8391.\n",
      "  4990. 11793.  7167. 10297.  6214.  8346.  5443.  9435.  6078. 11703.\n",
      "  6532.  8845.  8981.  7439.  6895.  7983. 10841.  9026.  5579.  9163.\n",
      "  4717.  7802.  5080.  9117.  4763.  8437. 14515.  9389. 12247.  9525.\n",
      "  4899.  7394.  8890.  8074.  8119. 15876.  9752.  5171.  8255.  7620.\n",
      "  6849.  7530.  7031.  6305.  6033. 11567.  6622.  8664. 10886.  9253.\n",
      "  4309.  5851.  6396.  9299.  4445. 12882.  9888.  4536. 11068.  4672.\n",
      "  5806.  7303.  9571. 13109.  7847.  6940.  8573.  6759. 10387. 12020.\n",
      "  8800.  5488. 11158.  5216.  7756. 12655.  9480. 12383.  8936.  7575.\n",
      "  6985. 11249.  8210. 10614.  5761.  7076. 14878.  9616.  6713.  4808.\n",
      " 16329. 10977. 10070. 14288.  6486. 11113. 12111.  5534. 10160.  9344.\n",
      " 11748. 12066.  6668.  4491. 13200. 10750. 10795.  3629. 10342.  8709.\n",
      "  8301.  5625.  9662.  9707.  7212.  4944. 12202.  9843. 12973.  7666.\n",
      " 18144.  5262. 12156. 11022.  4853. 14061. 15649. 11657.  8754.  4400.\n",
      " 12474. 11431.  3175.  9798. 10115. 11204. 10024. 11385. 15422. 11839.\n",
      " 13381. 14969.  4173. 11975. 13835. 15195. 12927. 13154. 10478. 13245.\n",
      " 10251. 11612.  4037. 13698. 19504.  9934.  5307. 13290. 12428. 11294.\n",
      " 11476. 10569.  4581. 11929. 16783.  5126. 16239.  4627. 12791. 12338.\n",
      "  3856. 13063. 14334. 11521. 16692. 10932. 13562. 20412. 12746. 11884.\n",
      " 13925. 12610. 13517. 12292. 15150. 17237. 13336.  4264.  5035. 14787.\n",
      "  3538. 14424. 14923.  3765.  8600. 14742. 28100. 16556. 16284. 15558.\n",
      "  7000. 13789. 18960. 20638. 14832.  4218. 15377.  3810.  9000. 17690.\n",
      " 19187. 24948.  6700.  9500. 17010.  6200.  4082.  5300. 13971. 13018.\n",
      "  3719. 10000. 16511.  6400.  4354.  2400. 13472. 14152. 12519.  7500.\n",
      "  6000.  3402. 16465. 25000.  5800.  5500.  8000.  8200.  5400.  7400.\n",
      " 15241.  3946. 22000.  4128. 16828. 19051. 18824.  5900.  4600. 26500.\n",
      " 23814. 16874. 14500. 19000.  9300. 15966.  7800.  5000. 18507. 10400.\n",
      " 16500. 18370.  3357. 16193.  6800. 13400.  3221. 20000. 14379. 17917.\n",
      "  6300. 21092.  6500.  3200.  3084.  7300.  8500.  7200. 17463. 12837.\n",
      "  8700.  3992. 13426.  7600. 15604. 12100. 15105.  8900. 14696. 14606.\n",
      "  9800. 16647. 17146. 22725.  2948. 19006. 16103.  3583. 22680. 17509.\n",
      " 13880. 24040. 15830. 17055. 12565.  6100. 13744.  5600. 14107. 15513.\n",
      "  5700.  3674.  2540.  9600.  6600. 11500.  4100.  4500. 17000. 15059.\n",
      " 27216.  3493.  2631.  4800.  3901.  8300. 23600.  2722. 19731.  5200.\n",
      " 15600.  8400.  9400.  2903.  4900.  7900. 15785. 19278. 14560. 25500.\n",
      " 10800. 18500.  6900. 22226. 22997.  7700.  8100.  9200.  2495.  7100.\n",
      " 10700. 10100. 12000. 20865. 14000. 11100. 11000. 14197.  2268. 13653.\n",
      " 21000. 14016. 14651.  2449. 15000. 10200. 22952.  2359.  3800. 13500.\n",
      " 17645. 15286. 23269. 12400. 19232. 18688. 11800. 16012. 16000. 20185.\n",
      " 14470. 18416. 16900. 16601.  3266. 18053.  4000. 17191. 14243. 15331.\n",
      "  2585. 16420. 21999. 18234.  3000. 16057.  4700. 21319. 27624. 19958.\n",
      " 17599. 21546.  5100. 21772. 20003. 23088. 18552. 10300. 14600. 18597.\n",
      " 17327.  9100. 17872. 15014. 15740. 16375. 19142. 10500. 17418.  2858.\n",
      "  9700. 25628.  3311. 15921. 20548. 16148. 17826. 17962. 20502. 20140.\n",
      " 16964. 23496. 17781. 20049. 23179. 22770. 27352. 18915. 15468. 16738.\n",
      " 21183. 22362. 22861.  3039. 19777. 25038. 19595. 18325. 29030. 28500.\n",
      " 11300. 24267. 23133. 18008. 20276. 18000. 18869. 16400. 15694. 11400.\n",
      " 12200. 24000. 22200. 13700.  2404. 18098. 27200. 17282. 27442. 23451.\n",
      " 19913. 24494. 20321.  2313. 26535. 17373. 19822. 26308. 11200. 15400.\n",
      " 23904. 20684. 17735. 22498.  3700. 12600. 27306. 20366. 23859. 19459.\n",
      " 18733. 22135. 22453. 21273. 23360. 19323. 22906. 23000. 24721.  9900.\n",
      "  2812. 23042. 18189. 17554. 23587. 20593. 18461. 17100. 13000.  2676.\n",
      " 21228. 28168. 19500. 16919. 25855. 21500.  2800. 12300. 18643. 11900.\n",
      " 21909. 27896. 18280. 13800. 21727. 24630. 18900. 21047.]\n",
      "_BMI5CAT : [nan  3.  2.  4.  1.]\n",
      "_RACE1 : [ 1.  2.  3.  7.  9.  8.  5.  4. nan]\n",
      "_AGEG5YR : [13.  8. 14.  5. 12. 11. 10.  9.  7.  6.  4.  3.  2.  1.]\n",
      "DIABETE4 : [1. 3. 4. 9. 2. 7.]\n",
      "PHYSHLTH : [88.  2.  1.  8.  5. 30.  4. 23. 14. 77. 15.  3. 10. 99.  7. 25.  6. 21.\n",
      " 20. 29. 16.  9. 27. 28. 12. 13. 11. 26. 17. 24. 18. 19. 22. nan]\n",
      "MENTHLTH : [88.  3.  9.  5. 15. 20. 14. 10. 18.  1. 77.  2. 30.  4. 99.  6.  7. 25.\n",
      "  8. 27. 21. 12. 16. 13. 28. 29. 26. 22. 17. 11. 19. 24. 23.]\n",
      "_TOTINDA : [2. 1. 9.]\n",
      "EXERANY2 : [2. 1. 7. 9.]\n",
      "SLEPTIM1 : [ 8.  6.  5.  7.  9.  4. 10.  1. 12. 77. 18.  3. 99.  2. 11. 15. 13. 16.\n",
      " 14. 20. 23. 24. 19. 21. 17. 22.]\n",
      "DISPCODE : [1100.]\n",
      "PRIMINSR : [99.  3.  1.  7.  2.  4. 10. 88.  5.  9. 77.  8.  6. nan]\n",
      "PERSDOC3 : [1. 2. 7. 3. 9.]\n",
      "CHECKUP1 : [ 1.  8.  7.  2.  3.  4.  9. nan]\n",
      "CVDINFR4 : [ 2.  1.  7.  9. nan]\n",
      "CVDCRHD4 : [2. 1. 7. 9.]\n",
      "CVDSTRK3 : [2. 1. 7. 9.]\n",
      "HAVARTH4 : [2. 1. 7. 9.]\n"
     ]
    }
   ],
   "source": [
    "# retrieve all labels and store in a list\n",
    "columns_df = list(gen_info_df.columns.values)\n",
    "# iterate over the list to print all unique values of each column in the dataframe\n",
    "for column in columns_df:\n",
    "    print(column, ':', str(gen_info_df[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ee53e",
   "metadata": {},
   "source": [
    "There were a lot of values in each columns that represents 'Dont know/Not sure' or 'Refused', for some column these values are coded by value 7 and 9 repectively and for others they are coded by 77 and 99. All of these values were converted to 'NaN' value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a95607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "004e3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns with 'Dont know/Not sure' or 'Refused' value as 7 or 9 \n",
    "columns = [\"HAVARTH4\", \"CVDSTRK3\", \"CVDCRHD4\", \"CVDINFR4\", \"CHECKUP1\", \"PERSDOC3\", \"EXERANY2\", \"_TOTINDA\", \n",
    "          \"DIABETE4\", \"_INCOMG1\"]\n",
    "\n",
    "#Iterate through each column and replace the value of 7 or 9 by NaN value\n",
    "for column in columns:\n",
    "    gen_info_df[column].replace({7 : np.nan}, inplace=True)\n",
    "    gen_info_df[column].replace({9 : np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76e9653d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAVARTH4 : [ 2.  1. nan]\n",
      "CVDSTRK3 : [ 2.  1. nan]\n",
      "CVDCRHD4 : [ 2.  1. nan]\n",
      "CVDINFR4 : [ 2.  1. nan]\n",
      "CHECKUP1 : [ 1.  8. nan  2.  3.  4.]\n",
      "PERSDOC3 : [ 1.  2. nan  3.]\n",
      "EXERANY2 : [ 2.  1. nan]\n",
      "_TOTINDA : [ 2.  1. nan]\n",
      "DIABETE4 : [ 1.  3.  4. nan  2.]\n",
      "_INCOMG1 : [nan  3.  6.  5.  4.  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# iterate over the list again to confirm that the changes are implemented successfully\n",
    "for column in columns:\n",
    "    print(column, ':', str(gen_info_df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1e17e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns with 'Dont know/Not sure' or 'Refused' value as 77 or 99 \n",
    "columns_2 = [\"PHYSHLTH\", \"MENTHLTH\", \"SLEPTIM1\", \"PRIMINSR\"]\n",
    "\n",
    "#Iterate through each column and replace the value of 77 or 99 by NaN value\n",
    "for column in columns_2:\n",
    "    gen_info_df[column].replace({77 : np.nan}, inplace=True)\n",
    "    gen_info_df[column].replace({99 : np.nan},  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8b427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for column \"HEIGHT3\", value 9999 represents \"Refused\" value, therefore replaced that value to NaN\n",
    "gen_info_df['HEIGHT3'].replace({9999 : np.nan},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccaafb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_STATE          0\n",
       "SEXVAR          0\n",
       "_INCOMG1    82890\n",
       "HEIGHT3      4738\n",
       "HTIN4       10766\n",
       "HTM4         7867\n",
       "WTKG3       18784\n",
       "_BMI5CAT    23406\n",
       "_RACE1          1\n",
       "_AGEG5YR        0\n",
       "DIABETE4      799\n",
       "PHYSHLTH     8139\n",
       "MENTHLTH     6742\n",
       "_TOTINDA      802\n",
       "EXERANY2      802\n",
       "SLEPTIM1     4027\n",
       "DISPCODE        0\n",
       "PRIMINSR    12334\n",
       "PERSDOC3     3116\n",
       "CHECKUP1     4289\n",
       "CVDINFR4     2235\n",
       "CVDCRHD4     3480\n",
       "CVDSTRK3     1166\n",
       "HAVARTH4     2030\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checked the null values for each column again\n",
    "gen_info_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "586be505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop all the NaN values\n",
    "gen_info_df = gen_info_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7c148f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>_INCOMG1</th>\n",
       "      <th>HEIGHT3</th>\n",
       "      <th>HTIN4</th>\n",
       "      <th>HTM4</th>\n",
       "      <th>WTKG3</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_RACE1</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>...</th>\n",
       "      <th>EXERANY2</th>\n",
       "      <th>SLEPTIM1</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>PRIMINSR</th>\n",
       "      <th>PERSDOC3</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>CVDINFR4</th>\n",
       "      <th>CVDCRHD4</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>HAVARTH4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>6804.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>6350.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>5398.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6260.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>7348.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445126</th>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10433.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445127</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>6985.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445128</th>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>8301.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445130</th>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445131</th>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>6350.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234134 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        _STATE  SEXVAR  _INCOMG1  HEIGHT3  HTIN4   HTM4    WTKG3  _BMI5CAT  \\\n",
       "1          1.0     2.0       3.0    503.0   63.0  160.0   6804.0       3.0   \n",
       "2          1.0     2.0       6.0    502.0   62.0  157.0   6350.0       3.0   \n",
       "4          1.0     2.0       3.0    502.0   62.0  157.0   5398.0       2.0   \n",
       "6          1.0     2.0       5.0    505.0   65.0  165.0   6260.0       2.0   \n",
       "7          1.0     2.0       5.0    504.0   64.0  163.0   7348.0       3.0   \n",
       "...        ...     ...       ...      ...    ...    ...      ...       ...   \n",
       "445126    78.0     1.0       5.0    600.0   72.0  183.0  10433.0       4.0   \n",
       "445127    78.0     2.0       1.0    505.0   65.0  165.0   6985.0       3.0   \n",
       "445128    78.0     2.0       5.0    507.0   67.0  170.0   8301.0       3.0   \n",
       "445130    78.0     1.0       5.0    600.0   72.0  183.0  10886.0       4.0   \n",
       "445131    78.0     1.0       2.0    506.0   66.0  168.0   6350.0       2.0   \n",
       "\n",
       "        _RACE1  _AGEG5YR  ...  EXERANY2  SLEPTIM1  DISPCODE  PRIMINSR  \\\n",
       "1          1.0      13.0  ...       2.0       6.0    1100.0       3.0   \n",
       "2          1.0       8.0  ...       1.0       5.0    1100.0       1.0   \n",
       "4          1.0       5.0  ...       1.0       9.0    1100.0       7.0   \n",
       "6          2.0      13.0  ...       1.0       7.0    1100.0       2.0   \n",
       "7          1.0      13.0  ...       2.0       8.0    1100.0       3.0   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "445126     1.0       3.0  ...       1.0       8.0    1100.0       1.0   \n",
       "445127     2.0       1.0  ...       1.0       6.0    1100.0       3.0   \n",
       "445128     2.0       7.0  ...       1.0       7.0    1100.0       1.0   \n",
       "445130     2.0      11.0  ...       2.0       5.0    1100.0       3.0   \n",
       "445131     2.0       5.0  ...       1.0       5.0    1100.0      88.0   \n",
       "\n",
       "        PERSDOC3  CHECKUP1  CVDINFR4  CVDCRHD4  CVDSTRK3  HAVARTH4  \n",
       "1            2.0       8.0       2.0       2.0       2.0       2.0  \n",
       "2            1.0       1.0       2.0       2.0       2.0       2.0  \n",
       "4            2.0       1.0       2.0       2.0       2.0       2.0  \n",
       "6            1.0       1.0       2.0       2.0       2.0       2.0  \n",
       "7            1.0       1.0       2.0       2.0       2.0       1.0  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "445126       3.0       2.0       2.0       2.0       2.0       2.0  \n",
       "445127       3.0       2.0       2.0       2.0       2.0       2.0  \n",
       "445128       2.0       1.0       2.0       2.0       2.0       2.0  \n",
       "445130       2.0       1.0       1.0       2.0       2.0       2.0  \n",
       "445131       3.0       8.0       2.0       2.0       2.0       2.0  \n",
       "\n",
       "[234134 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataframe \n",
    "gen_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29dd8d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_STATE : [ 1.  2.  4.  5.  6.  8.  9. 10. 11. 12. 13. 15. 16. 17. 18. 19. 20. 21.\n",
      " 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35. 36. 37. 38. 39.\n",
      " 40. 41. 42. 44. 45. 46. 47. 48. 49. 50. 51. 53. 54. 55. 56. 66. 72. 78.]\n",
      "SEXVAR : [2. 1.]\n",
      "_INCOMG1 : [3. 6. 5. 4. 1. 2.]\n",
      "HEIGHT3 : [503. 502. 505. 504. 506. 508. 511. 602. 601. 509. 500. 600. 507. 510.\n",
      " 605. 501. 603. 411. 604. 410. 606. 409. 408. 405. 607. 608. 701. 403.\n",
      " 407. 406. 700. 611. 300. 404. 311. 610. 702. 609. 402. 400. 306. 705.\n",
      " 703. 401. 704. 308. 305. 302. 706. 711. 708.]\n",
      "HTIN4 : [63. 62. 65. 64. 66. 68. 71. 74. 73. 69. 60. 72. 67. 70. 77. 61. 75. 59.\n",
      " 76. 58. 78. 57. 56. 53. 79. 80. 85. 51. 55. 54. 84. 83. 36. 52. 47. 82.\n",
      " 86. 81. 50. 48. 42. 89. 87. 49. 88. 44. 41. 38. 90. 95. 92.]\n",
      "HTM4 : [160. 157. 165. 163. 168. 173. 180. 188. 185. 175. 152. 183. 170. 178.\n",
      " 196. 155. 191. 150. 193. 147. 198. 145. 142. 135. 201. 203. 216. 130.\n",
      " 140. 137. 213. 211.  91. 132. 119. 208. 218. 206. 127. 122. 107. 226.\n",
      " 221. 124. 224. 112. 104.  97. 229. 241. 234.]\n",
      "WTKG3 : [ 6804.  6350.  5398.  6260.  7348.  8165.  7484.  8528. 10659.  7121.\n",
      "  6441.  9072.  6577.  8029.  8618.  5715. 10523.  7711.  7938. 10206.\n",
      "  5987. 10433.  6169. 13608.  9979. 12701.  5897.  9208.  8391.  8482.\n",
      " 11793. 10297.  8346.  5443.  6123.  6078. 11703.  8845.  8981.  6895.\n",
      "  7983. 10841.  4990.  7893. 11340.  5080.  9117.  4763.  7257.  8437.\n",
      " 14515.  9389.  9525.  8890.  8074. 15876.  9752.  5171.  8119.  7394.\n",
      "  8255.  7620.  7530.  7031.  5670. 11567.  6622.  8664. 10886.  7167.\n",
      "  9253.  6396.  9299. 12882.  4672.  5806.  7303.  9571.  7847.  6759.\n",
      " 12020.  7802. 12247.  5488.  5216.  7756. 12655. 12383.  7575.  6985.\n",
      "  9163. 11249.  6849.  8210. 10614.  7076. 14878.  9616.  9435.  6713.\n",
      "  4808. 10977. 10070. 14288.  6486.  4536.  9888. 12111.  5534.  9344.\n",
      " 11748. 16329. 12066.  4491.  8573. 13200. 10750.  7439. 11113.  3629.\n",
      " 10342.  8709.  8301.  5625.  9662.  6668.  6940.  5851.  6305.  4944.\n",
      " 12202. 10705. 12973.  7666.  4899. 18144.  6532.  5262. 12156. 11022.\n",
      "  9480.  6214.  4853. 14061.  5942.  5761.  5579.  9707.  8754. 11431.\n",
      " 10115. 11204.  9843. 10024. 11385. 15422. 11839. 13381. 11068. 14969.\n",
      "  6033.  4173. 11975. 13835. 15195. 11657. 11158. 12927. 13154.  8800.\n",
      " 12474. 10478. 10795. 10251.  9798.  8936. 11612.  5352. 19504.  9934.\n",
      "  5307. 13290. 12428. 11294. 10160.  4581. 11929.  7212. 13698. 16239.\n",
      " 12791. 14334. 11521.  9026. 16692. 10932. 13562. 20412. 12746. 10569.\n",
      "  4627. 13925. 12610.  3856. 13517. 12292. 13109. 10387.  4264. 11884.\n",
      "  5035.  4717.  4309.  3538. 12338. 11476. 16783.  3765. 14742. 16556.\n",
      " 17237. 16284. 15558.  7000. 13789. 13063. 20638. 14832.  4445. 15377.\n",
      "  9000. 19187. 24948.  9500. 17010.  6200.  4400.  4082. 13971.  5126.\n",
      " 13018. 14424.  3719. 10000.  4354. 13472.  4218. 14152. 12519.  5800.\n",
      " 15649.  8200. 15241. 13336. 19051. 18824.  4600. 26500. 23814. 16874.\n",
      "  5500. 15966.  3810. 18507. 18370. 16193. 13400.  3221.  9300. 14379.\n",
      " 17917. 12837. 17690.  3992. 13426.  6500. 12100.  8900. 14696. 14606.\n",
      "  9800. 17146. 17463.  3946.  2948. 19006. 16103.  3583. 22680.  8700.\n",
      " 13880. 13245. 24040. 15830. 12565. 13744. 14107.  8500.  9600.  5000.\n",
      "  6300.  7600.  4100.  8600.  8000.  5700. 15059.  4500.  7800. 19731.\n",
      " 15600.  7300.  4900. 15785. 22226. 22997.  6700.  6000. 10100. 15513.\n",
      " 20865. 14923.  7500.  4128.  7200.  7900.  5200. 15105.  5900. 13653.\n",
      " 14016.  6900. 14651.  7400.  9200.  5600. 10200. 22952. 15150.  3674.\n",
      "  3402.  7100. 13500. 17645. 14787. 15286.  3175. 17000. 12400.  3901.\n",
      " 19232. 18688.  4037. 17055. 20185. 14470. 18416. 17509. 16601. 18053.\n",
      " 15604.  8100. 17191. 14243. 15331.  6800. 16420. 21999.  5400. 14197.\n",
      "  3447.  6600. 21319.  8400. 11500. 27624. 16012. 19958. 17599. 21546.\n",
      "  4800. 20003. 23088.  3357. 18552. 17327. 17872. 16057.  9100. 19278.\n",
      " 15014. 14500. 16375. 21772. 19142. 17418. 16465. 25628.  3311. 15921.\n",
      " 20548. 16148. 17826.  7700. 17962. 20502. 15740. 16647. 16964. 20049.\n",
      " 14560. 18915. 27216. 15468.  6100. 16738. 21183. 22362. 22861. 16511.\n",
      " 19777. 18597. 10800.  5300. 25038. 19595. 18325. 11000. 23133. 18008.\n",
      " 18000. 11400. 12200. 18098. 11800. 27442. 18869. 10700. 23451. 24494.\n",
      " 20321. 17781. 17373. 19822. 11200.  9400. 15400. 20684. 17735.  8300.\n",
      " 27306. 20366. 23859. 19459. 11300. 18733. 22135.  6400. 22453. 14600.\n",
      " 20140. 15694. 23360. 19323. 22725. 22906. 18189. 17554. 23587. 20593.\n",
      " 18461. 17100. 21228. 13000. 19500. 16919.  3084. 16828. 12300.  3266.\n",
      "  9700. 18280. 13800.  4700. 21727. 16000. 12000. 20000. 24630.  3039.]\n",
      "_BMI5CAT : [3. 2. 4. 1.]\n",
      "_RACE1 : [1. 2. 7. 3. 9. 8. 4. 5.]\n",
      "_AGEG5YR : [13.  8.  5. 11. 10.  9. 12.  7.  6.  4. 14.  3.  2.  1.]\n",
      "DIABETE4 : [3. 1. 4. 2.]\n",
      "PHYSHLTH : [88.  2.  1.  8.  5. 30.  4. 23. 15.  3. 10.  7. 14. 25. 21. 20. 29.  6.\n",
      "  9. 27. 13. 12. 28. 26. 17. 16. 24. 11. 18. 19. 22.]\n",
      "MENTHLTH : [88.  3.  9.  5. 15. 10. 18.  1.  2.  4.  7. 20.  6. 30. 14.  8. 25. 27.\n",
      " 12. 13. 21. 28. 29. 26. 17. 11. 16. 22. 19. 24. 23.]\n",
      "_TOTINDA : [2. 1.]\n",
      "EXERANY2 : [2. 1.]\n",
      "SLEPTIM1 : [ 6.  5.  9.  7.  8.  4. 10.  1. 12.  3.  2. 18. 11. 13. 15. 16. 14. 23.\n",
      " 20. 17. 22. 24. 19.]\n",
      "DISPCODE : [1100.]\n",
      "PRIMINSR : [ 3.  1.  7.  2.  4. 10.  5. 88.  9.  8.  6.]\n",
      "PERSDOC3 : [2. 1. 3.]\n",
      "CHECKUP1 : [8. 1. 2. 3. 4.]\n",
      "CVDINFR4 : [2. 1.]\n",
      "CVDCRHD4 : [2. 1.]\n",
      "CVDSTRK3 : [2. 1.]\n",
      "HAVARTH4 : [2. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Cross-check again the unique values in each confirm to make sure all the rows with 'Dont know/Not sure' or 'Refused'\n",
    "# and NaN values are removed\n",
    "\n",
    "\n",
    "#retrieve all labels and store in a list\n",
    "columns_3 = list(gen_info_df.columns.values)\n",
    "# iterate over the list to print all unique values of each column in the dataframe\n",
    "for column in columns_df:\n",
    "    print(column, ':', str(gen_info_df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2dbcb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data cleaned data into a .csv file\n",
    "gen_info_df.to_csv('cleaned_diabetes_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56307c6",
   "metadata": {},
   "source": [
    "## 1. Importing the dataframe into pgAdmin 4 using sqlachemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "923d365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules for connecting to pgAdmin4\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d8e2cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters unique to the database from AWS RDS\n",
    "hostname = 'diabetes-dataset.cwpas6tssjkb.us-east-1.rds.amazonaws.com'\n",
    "database = 'diabetes_database'\n",
    "username = 'dspataru' #input username manually\n",
    "password = 'dbpassSCS' #input password manually\n",
    "port_id = 5432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08f63bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port_id}/{database}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbca02e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_info_df.to_sql('general_info', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a375a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data[['DISPCODE', #completed interviews=1200\n",
    "                'DIABETE4', #diabetes\n",
    "                 'PDIABTS1', #When was your last blood test for high blood sugar?\n",
    "                 'CHKHEMO3', #Times Checked for Glycosylated Hemoglobin \n",
    "                 '_BMI5CAT', #BMI\n",
    "                 '_SMOKER3', #smoking\n",
    "                 'EYEEXAM1', 'DIABEYE1', #eye related stuff\n",
    "                 'CVDSTRK3', '_MICHD', #chronic health conditions\n",
    "                 '_TOTINDA', #physical activity\n",
    "                 '_RFDRHV8', #alcohol consumption\n",
    "                 '_HLTHPLN', 'MEDCOST1', #health care providers\n",
    "                 'GENHLTH', 'MENTHLTH', 'PHYSHLTH', 'DIFFWALK', #health general and mental health\n",
    "                 'SEXVAR', '_AGEG5YR', '_EDUCAG', 'INCOME3' ]] #demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7549976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>PDIABTS1</th>\n",
       "      <th>CHKHEMO3</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>EYEEXAM1</th>\n",
       "      <th>DIABEYE1</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>...</th>\n",
       "      <th>_HLTHPLN</th>\n",
       "      <th>MEDCOST1</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>INCOME3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISPCODE  DIABETE4  PDIABTS1  CHKHEMO3  _BMI5CAT  _SMOKER3  EYEEXAM1  \\\n",
       "0    1100.0       1.0       NaN       NaN       NaN       4.0       NaN   \n",
       "1    1100.0       3.0       NaN       NaN       3.0       4.0       NaN   \n",
       "2    1100.0       3.0       NaN       NaN       3.0       4.0       NaN   \n",
       "3    1100.0       3.0       NaN       NaN       2.0       2.0       NaN   \n",
       "4    1100.0       3.0       NaN       NaN       2.0       4.0       NaN   \n",
       "\n",
       "   DIABEYE1  CVDSTRK3  _MICHD  ...  _HLTHPLN  MEDCOST1  GENHLTH  MENTHLTH  \\\n",
       "0       NaN       2.0     2.0  ...       9.0       2.0      2.0      88.0   \n",
       "1       NaN       2.0     2.0  ...       1.0       2.0      1.0      88.0   \n",
       "2       NaN       2.0     2.0  ...       1.0       2.0      2.0       3.0   \n",
       "3       NaN       2.0     2.0  ...       9.0       2.0      1.0      88.0   \n",
       "4       NaN       2.0     2.0  ...       1.0       2.0      4.0      88.0   \n",
       "\n",
       "   PHYSHLTH  DIFFWALK  SEXVAR  _AGEG5YR  _EDUCAG  INCOME3  \n",
       "0      88.0       2.0     2.0      13.0      4.0     99.0  \n",
       "1      88.0       2.0     2.0      13.0      2.0      5.0  \n",
       "2       2.0       2.0     2.0       8.0      4.0     10.0  \n",
       "3      88.0       2.0     2.0      14.0      2.0     77.0  \n",
       "4       2.0       2.0     2.0       5.0      3.0      5.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3037ac34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>PDIABTS1</th>\n",
       "      <th>CHKHEMO3</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>EYEEXAM1</th>\n",
       "      <th>DIABEYE1</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>...</th>\n",
       "      <th>_HLTHPLN</th>\n",
       "      <th>MEDCOST1</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>INCOME3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445127</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445128</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445129</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445130</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445131</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DISPCODE  DIABETE4  PDIABTS1  CHKHEMO3  _BMI5CAT  _SMOKER3  EYEEXAM1  \\\n",
       "445127    1100.0       3.0       7.0       NaN       3.0       4.0       NaN   \n",
       "445128    1100.0       3.0       1.0       NaN       3.0       4.0       NaN   \n",
       "445129    1100.0       3.0       7.0       NaN       1.0       1.0       NaN   \n",
       "445130    1100.0       3.0       1.0       NaN       4.0       4.0       NaN   \n",
       "445131    1100.0       3.0       1.0       NaN       2.0       3.0       NaN   \n",
       "\n",
       "        DIABEYE1  CVDSTRK3  _MICHD  ...  _HLTHPLN  MEDCOST1  GENHLTH  \\\n",
       "445127       NaN       2.0     2.0  ...       1.0       2.0      3.0   \n",
       "445128       NaN       2.0     2.0  ...       1.0       2.0      1.0   \n",
       "445129       NaN       2.0     2.0  ...       2.0       1.0      5.0   \n",
       "445130       NaN       2.0     1.0  ...       1.0       2.0      2.0   \n",
       "445131       NaN       2.0     2.0  ...       2.0       1.0      2.0   \n",
       "\n",
       "        MENTHLTH  PHYSHLTH  DIFFWALK  SEXVAR  _AGEG5YR  _EDUCAG  INCOME3  \n",
       "445127       3.0      88.0       2.0     2.0       1.0      2.0      1.0  \n",
       "445128       2.0       2.0       2.0     2.0       7.0      4.0      7.0  \n",
       "445129      30.0      30.0       2.0     2.0      10.0      2.0     77.0  \n",
       "445130      88.0      88.0       2.0     1.0      11.0      3.0      8.0  \n",
       "445131       1.0      88.0       1.0     1.0       5.0      1.0      4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = raw_data[(raw_data['DISPCODE'] == 1100)]\n",
    "raw_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b305315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(353271, 22)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ab87e",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf519c",
   "metadata": {},
   "source": [
    "#### 2.1 Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4b34b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 353271 entries, 0 to 445131\n",
      "Data columns (total 22 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   DISPCODE  353271 non-null  float64\n",
      " 1   DIABETE4  353271 non-null  float64\n",
      " 2   PDIABTS1  119253 non-null  float64\n",
      " 3   CHKHEMO3  10776 non-null   float64\n",
      " 4   _BMI5CAT  329865 non-null  float64\n",
      " 5   _SMOKER3  353271 non-null  float64\n",
      " 6   EYEEXAM1  10776 non-null   float64\n",
      " 7   DIABEYE1  10776 non-null   float64\n",
      " 8   CVDSTRK3  353271 non-null  float64\n",
      " 9   _MICHD    349441 non-null  float64\n",
      " 10  _TOTINDA  353271 non-null  float64\n",
      " 11  _RFDRHV8  353271 non-null  float64\n",
      " 12  _HLTHPLN  353271 non-null  float64\n",
      " 13  MEDCOST1  353269 non-null  float64\n",
      " 14  GENHLTH   353270 non-null  float64\n",
      " 15  MENTHLTH  353271 non-null  float64\n",
      " 16  PHYSHLTH  353270 non-null  float64\n",
      " 17  DIFFWALK  353270 non-null  float64\n",
      " 18  SEXVAR    353271 non-null  float64\n",
      " 19  _AGEG5YR  353271 non-null  float64\n",
      " 20  _EDUCAG   353271 non-null  float64\n",
      " 21  INCOME3   353269 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 62.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(raw_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6cf41079",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = raw_data.drop(columns=['CHKHEMO3','EYEEXAM1','DIABEYE1', 'PDIABTS1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3affd637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>_RFDRHV8</th>\n",
       "      <th>_HLTHPLN</th>\n",
       "      <th>MEDCOST1</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>INCOME3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445127</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445128</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445129</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445130</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445131</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353271 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DISPCODE  DIABETE4  _BMI5CAT  _SMOKER3  CVDSTRK3  _MICHD  _TOTINDA  \\\n",
       "0         1100.0       1.0       NaN       4.0       2.0     2.0       2.0   \n",
       "1         1100.0       3.0       3.0       4.0       2.0     2.0       2.0   \n",
       "2         1100.0       3.0       3.0       4.0       2.0     2.0       1.0   \n",
       "3         1100.0       3.0       2.0       2.0       2.0     2.0       1.0   \n",
       "4         1100.0       3.0       2.0       4.0       2.0     2.0       1.0   \n",
       "...          ...       ...       ...       ...       ...     ...       ...   \n",
       "445127    1100.0       3.0       3.0       4.0       2.0     2.0       1.0   \n",
       "445128    1100.0       3.0       3.0       4.0       2.0     2.0       1.0   \n",
       "445129    1100.0       3.0       1.0       1.0       2.0     2.0       2.0   \n",
       "445130    1100.0       3.0       4.0       4.0       2.0     1.0       2.0   \n",
       "445131    1100.0       3.0       2.0       3.0       2.0     2.0       1.0   \n",
       "\n",
       "        _RFDRHV8  _HLTHPLN  MEDCOST1  GENHLTH  MENTHLTH  PHYSHLTH  DIFFWALK  \\\n",
       "0            1.0       9.0       2.0      2.0      88.0      88.0       2.0   \n",
       "1            1.0       1.0       2.0      1.0      88.0      88.0       2.0   \n",
       "2            1.0       1.0       2.0      2.0       3.0       2.0       2.0   \n",
       "3            1.0       9.0       2.0      1.0      88.0      88.0       2.0   \n",
       "4            1.0       1.0       2.0      4.0      88.0       2.0       2.0   \n",
       "...          ...       ...       ...      ...       ...       ...       ...   \n",
       "445127       9.0       1.0       2.0      3.0       3.0      88.0       2.0   \n",
       "445128       1.0       1.0       2.0      1.0       2.0       2.0       2.0   \n",
       "445129       9.0       2.0       1.0      5.0      30.0      30.0       2.0   \n",
       "445130       1.0       1.0       2.0      2.0      88.0      88.0       2.0   \n",
       "445131       9.0       2.0       1.0      2.0       1.0      88.0       1.0   \n",
       "\n",
       "        SEXVAR  _AGEG5YR  _EDUCAG  INCOME3  \n",
       "0          2.0      13.0      4.0     99.0  \n",
       "1          2.0      13.0      2.0      5.0  \n",
       "2          2.0       8.0      4.0     10.0  \n",
       "3          2.0      14.0      2.0     77.0  \n",
       "4          2.0       5.0      3.0      5.0  \n",
       "...        ...       ...      ...      ...  \n",
       "445127     2.0       1.0      2.0      1.0  \n",
       "445128     2.0       7.0      4.0      7.0  \n",
       "445129     2.0      10.0      2.0     77.0  \n",
       "445130     1.0      11.0      3.0      8.0  \n",
       "445131     1.0       5.0      1.0      4.0  \n",
       "\n",
       "[353271 rows x 18 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2eca707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326519, 17)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = raw_data.dropna()\n",
    "cleaned_data = cleaned_data.drop(columns=['DISPCODE'])\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d468e2",
   "metadata": {},
   "source": [
    "#### 2.2 Modify and clean the values to be more suitable to ML algorithms\n",
    "In order to be able to do this part, each column in the dataset was reviewed against the codebook which says what each column is, and what the values in each column correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9fd18f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    272252\n",
       "2.0     45898\n",
       "1.0      7883\n",
       "Name: DIABETE4, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIABETE4\n",
    "# for the machine learning model, we are interested in knowing if someone has diabetes, or is trending towards diabetes\n",
    "# 0 = no diabetes or only told during pregnency for females ('no')\n",
    "# 1 = pre-diabetes or borderline diabetes ('no')\n",
    "# 2 = diabetes ('yes')\n",
    "# we will remove the \"Don't know/Not Sure\" and \"Refused\" data points\n",
    "cleaned_data['DIABETE4'] = cleaned_data['DIABETE4'].replace({1:2, 2:0, 3:0, 4:1})\n",
    "cleaned_data = cleaned_data[cleaned_data.DIABETE4 != 7]\n",
    "cleaned_data = cleaned_data[cleaned_data.DIABETE4 != 9]\n",
    "cleaned_data.DIABETE4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d9294d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    192843\n",
       "1.0    131104\n",
       "Name: _SMOKER3, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _SMOKER3\n",
    "# creating two buckets:\n",
    "# 0 = never smoked\n",
    "# 1 = used to smoke or still smokes\n",
    "# we will remove the Dont know/Refused/Missing\n",
    "cleaned_data['_SMOKER3'] = cleaned_data['_SMOKER3'].replace({1:1, 2:1, 3:1, 4:0})\n",
    "cleaned_data = cleaned_data[cleaned_data._SMOKER3 != 9]\n",
    "cleaned_data._SMOKER3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a4ca2aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    309011\n",
       "1.0     14227\n",
       "Name: CVDSTRK3, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CVDSTRK3\n",
    "# we will remove the Dont know/Refused and keep only the yes ('1') and no ('2')\n",
    "# replace 2 with 0\n",
    "cleaned_data['CVDSTRK3'] = cleaned_data['CVDSTRK3'].replace({2:0})\n",
    "cleaned_data = cleaned_data[cleaned_data.CVDSTRK3 != 7]\n",
    "cleaned_data = cleaned_data[cleaned_data.CVDSTRK3 != 9]\n",
    "cleaned_data.CVDSTRK3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "74f4e6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    292661\n",
       "1.0     30577\n",
       "Name: _MICHD, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _MICHD\n",
    "# change 2 to 0 because this means did not have MI or CHD\n",
    "cleaned_data['_MICHD'] = cleaned_data['_MICHD'].replace({2: 0})\n",
    "cleaned_data._MICHD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a16fef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    247110\n",
       "0.0     75563\n",
       "Name: _TOTINDA, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _TOTINDA\n",
    "# 1 for physical activity\n",
    "# change 2 to 0 for no physical activity\n",
    "# Remove all 9 (don't know/refused)\n",
    "cleaned_data['_TOTINDA'] = cleaned_data['_TOTINDA'].replace({2:0})\n",
    "cleaned_data = cleaned_data[cleaned_data._TOTINDA != 9]\n",
    "cleaned_data._TOTINDA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ec3a871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    296151\n",
       "1.0     21472\n",
       "Name: _RFDRHV8, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _RFDRHV8\n",
    "# Change 1 to 0 (1 was no for heavy drinking). change all 2 to 1 (2 was yes for heavy drinking)\n",
    "# remove all dont knows and missing 9\n",
    "cleaned_data['_RFDRHV8'] = cleaned_data['_RFDRHV8'].replace({1:0, 2:1})\n",
    "cleaned_data = cleaned_data[cleaned_data._RFDRHV8 != 9]\n",
    "cleaned_data._RFDRHV8.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "96b0fedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    293940\n",
       "1.0     14297\n",
       "Name: _HLTHPLN, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _HLTHPLN\n",
    "# 1 is yes, change 2 to 0 because it is No health care access\n",
    "# remove 9 for don't know or refused\n",
    "cleaned_data['_HLTHPLN'] = cleaned_data['_HLTHPLN'].replace({1:0, 2:1})\n",
    "cleaned_data = cleaned_data[cleaned_data._HLTHPLN != 9]\n",
    "cleaned_data._HLTHPLN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "27f467ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    283823\n",
       "1.0     23754\n",
       "Name: MEDCOST1, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEDCOST1\n",
    "# Change 2 to 0 for no, 1 is already yes\n",
    "# remove 7 for don/t know and 9 for refused\n",
    "cleaned_data['MEDCOST1'] = cleaned_data['MEDCOST1'].replace({2:0})\n",
    "cleaned_data = cleaned_data[cleaned_data.MEDCOST1 != 7]\n",
    "cleaned_data = cleaned_data[cleaned_data.MEDCOST1 != 9]\n",
    "cleaned_data.MEDCOST1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7803444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    106073\n",
       "3.0     98191\n",
       "1.0     48610\n",
       "4.0     41131\n",
       "5.0     13006\n",
       "Name: GENHLTH, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GENHLTH\n",
    "# Remove 7 and 9 for don't know and refused\n",
    "cleaned_data = cleaned_data[cleaned_data.GENHLTH != 7]\n",
    "cleaned_data = cleaned_data[cleaned_data.GENHLTH != 9]\n",
    "cleaned_data.GENHLTH.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5d2dfd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     183282\n",
       "30.0     17882\n",
       "2.0      16998\n",
       "5.0      14121\n",
       "3.0      10806\n",
       "10.0     10730\n",
       "1.0      10284\n",
       "15.0     10194\n",
       "20.0      6293\n",
       "4.0       5700\n",
       "7.0       5492\n",
       "25.0      2100\n",
       "14.0      1962\n",
       "6.0       1620\n",
       "8.0       1227\n",
       "12.0       872\n",
       "28.0       627\n",
       "21.0       384\n",
       "29.0       323\n",
       "18.0       203\n",
       "9.0        203\n",
       "16.0       190\n",
       "17.0       162\n",
       "27.0       155\n",
       "22.0       137\n",
       "13.0       114\n",
       "11.0        85\n",
       "24.0        84\n",
       "26.0        80\n",
       "23.0        66\n",
       "19.0        30\n",
       "Name: MENTHLTH, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MENTHLTH\n",
    "# change 88 to 0 because it means no\n",
    "# remove 77 and 99 for don't know/not sure and refused\n",
    "cleaned_data['MENTHLTH'] = cleaned_data['MENTHLTH'].replace({88:0})\n",
    "cleaned_data = cleaned_data[cleaned_data.MENTHLTH != 77]\n",
    "cleaned_data = cleaned_data[cleaned_data.MENTHLTH != 99]\n",
    "cleaned_data.MENTHLTH.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "863fb0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     182574\n",
       "30.0     22235\n",
       "2.0      17751\n",
       "1.0      12135\n",
       "3.0      11243\n",
       "5.0      10816\n",
       "10.0      7433\n",
       "7.0       6471\n",
       "15.0      6062\n",
       "4.0       6011\n",
       "20.0      3692\n",
       "14.0      3469\n",
       "6.0       1737\n",
       "25.0      1441\n",
       "8.0       1209\n",
       "12.0       779\n",
       "21.0       727\n",
       "28.0       473\n",
       "9.0        282\n",
       "29.0       229\n",
       "18.0       192\n",
       "16.0       163\n",
       "17.0       135\n",
       "27.0       128\n",
       "11.0       114\n",
       "13.0       104\n",
       "22.0        78\n",
       "24.0        76\n",
       "26.0        69\n",
       "23.0        68\n",
       "19.0        33\n",
       "Name: PHYSHLTH, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PHYSHLTH\n",
    "# same manipulatins as above\n",
    "cleaned_data['PHYSHLTH'] = cleaned_data['PHYSHLTH'].replace({88:0})\n",
    "cleaned_data = cleaned_data[cleaned_data.PHYSHLTH != 77]\n",
    "cleaned_data = cleaned_data[cleaned_data.PHYSHLTH != 99]\n",
    "cleaned_data.PHYSHLTH.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e97c8b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    251235\n",
       "1.0     45986\n",
       "Name: DIFFWALK, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DIFFWALK\n",
    "# change 2 to 0 for no. 1 is already yes\n",
    "# remove 7 and 9 for don't know not sure and refused\n",
    "cleaned_data['DIFFWALK'] = cleaned_data['DIFFWALK'].replace({2:0})\n",
    "cleaned_data = cleaned_data[cleaned_data.DIFFWALK != 7]\n",
    "cleaned_data = cleaned_data[cleaned_data.DIFFWALK != 9]\n",
    "cleaned_data.DIFFWALK.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ec027207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    154657\n",
       "1.0    142564\n",
       "Name: SEXVAR, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SEXVAR\n",
    "# 0 for female, 1 for male\n",
    "cleaned_data['SEXVAR'] = cleaned_data['SEXVAR'].replace({2:0})\n",
    "cleaned_data.SEXVAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "165a9d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0    33885\n",
       "11.0    31296\n",
       "9.0     31236\n",
       "8.0     25769\n",
       "13.0    23731\n",
       "7.0     23250\n",
       "12.0    22964\n",
       "5.0     20093\n",
       "6.0     19319\n",
       "4.0     18744\n",
       "3.0     16124\n",
       "1.0     14807\n",
       "2.0     13494\n",
       "Name: _AGEG5YR, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _AGEG5YR\n",
    "# remove 14 for don't know/refused\n",
    "cleaned_data = cleaned_data[cleaned_data._AGEG5YR != 14]\n",
    "cleaned_data._AGEG5YR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c283404a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    131234\n",
       "3.0     80928\n",
       "2.0     68289\n",
       "1.0     13855\n",
       "Name: _EDUCAG, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _EDUCAG\n",
    "# remove 9 for don't know/refused\n",
    "cleaned_data = cleaned_data[cleaned_data._EDUCAG != 9]\n",
    "cleaned_data._EDUCAG.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "431a36d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0     43872\n",
       "9.0     38383\n",
       "8.0     36519\n",
       "6.0     33284\n",
       "5.0     28757\n",
       "11.0    17866\n",
       "10.0    17133\n",
       "4.0     13788\n",
       "3.0      9554\n",
       "2.0      7348\n",
       "1.0      6384\n",
       "Name: INCOME3, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INCOME3\n",
    "# Remove 77 and 99 for don't know and refused\n",
    "cleaned_data = cleaned_data[cleaned_data.INCOME3 != 77]\n",
    "cleaned_data = cleaned_data[cleaned_data.INCOME3 != 99]\n",
    "cleaned_data.INCOME3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7674d5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252888, 17)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b7e8b21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIABETE4</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>_MICHD</th>\n",
       "      <th>_TOTINDA</th>\n",
       "      <th>_RFDRHV8</th>\n",
       "      <th>_HLTHPLN</th>\n",
       "      <th>MEDCOST1</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>DIFFWALK</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>INCOME3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DIABETE4  _BMI5CAT  _SMOKER3  CVDSTRK3  _MICHD  _TOTINDA  _RFDRHV8  \\\n",
       "1       0.0       3.0       0.0       0.0     0.0       0.0       0.0   \n",
       "2       0.0       3.0       0.0       0.0     0.0       1.0       0.0   \n",
       "4       0.0       2.0       0.0       0.0     0.0       1.0       0.0   \n",
       "6       0.0       2.0       1.0       0.0     0.0       1.0       0.0   \n",
       "7       0.0       3.0       0.0       0.0     0.0       0.0       0.0   \n",
       "\n",
       "   _HLTHPLN  MEDCOST1  GENHLTH  MENTHLTH  PHYSHLTH  DIFFWALK  SEXVAR  \\\n",
       "1       0.0       0.0      1.0       0.0       0.0       0.0     0.0   \n",
       "2       0.0       0.0      2.0       3.0       2.0       0.0     0.0   \n",
       "4       0.0       0.0      4.0       0.0       2.0       0.0     0.0   \n",
       "6       0.0       0.0      2.0       0.0       0.0       0.0     0.0   \n",
       "7       0.0       0.0      3.0       0.0       0.0       0.0     0.0   \n",
       "\n",
       "   _AGEG5YR  _EDUCAG  INCOME3  \n",
       "1      13.0      2.0      5.0  \n",
       "2       8.0      4.0     10.0  \n",
       "4       5.0      3.0      5.0  \n",
       "6      13.0      4.0      8.0  \n",
       "7      13.0      2.0      7.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1395c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIABETE4\n",
       "0.0    211801\n",
       "1.0      5893\n",
       "2.0     35194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check class sizes of the diabetes column (target variable)\n",
    "cleaned_data.groupby(['DIABETE4']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c074365",
   "metadata": {},
   "source": [
    "#### 2.3 Modify feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6c86b4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>BMICategory</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>HealthcarePlan</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>DifficultyWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes  BMICategory  Smoker  Stroke  HeartDiseaseorAttack  PhysActivity  \\\n",
       "1       0.0          3.0     0.0     0.0                   0.0           0.0   \n",
       "2       0.0          3.0     0.0     0.0                   0.0           1.0   \n",
       "4       0.0          2.0     0.0     0.0                   0.0           1.0   \n",
       "6       0.0          2.0     1.0     0.0                   0.0           1.0   \n",
       "7       0.0          3.0     0.0     0.0                   0.0           0.0   \n",
       "\n",
       "   HvyAlcoholConsump  HealthcarePlan  NoDocbcCost  GeneralHealth  \\\n",
       "1                0.0             0.0          0.0            1.0   \n",
       "2                0.0             0.0          0.0            2.0   \n",
       "4                0.0             0.0          0.0            4.0   \n",
       "6                0.0             0.0          0.0            2.0   \n",
       "7                0.0             0.0          0.0            3.0   \n",
       "\n",
       "   MentalHealth  PhysicalHealth  DifficultyWalking  Sex  AgeCategory  \\\n",
       "1           0.0             0.0                0.0  0.0         13.0   \n",
       "2           3.0             2.0                0.0  0.0          8.0   \n",
       "4           0.0             2.0                0.0  0.0          5.0   \n",
       "6           0.0             0.0                0.0  0.0         13.0   \n",
       "7           0.0             0.0                0.0  0.0         13.0   \n",
       "\n",
       "   EducationLevel  Income  \n",
       "1             2.0     5.0  \n",
       "2             4.0    10.0  \n",
       "4             3.0     5.0  \n",
       "6             4.0     8.0  \n",
       "7             2.0     7.0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = cleaned_data.rename(columns = {'DIABETE4':'Diabetes', \n",
    "                                         '_BMI5CAT':'BMICategory', \n",
    "                                         '_SMOKER3':'Smoker', \n",
    "                                         'CVDSTRK3':'Stroke', '_MICHD':'HeartDiseaseorAttack', \n",
    "                                         '_TOTINDA':'PhysActivity', \n",
    "                                         '_RFDRHV8':'HvyAlcoholConsump', \n",
    "                                         '_HLTHPLN':'HealthcarePlan', 'MEDCOST1':'NoDocbcCost', \n",
    "                                         'GENHLTH':'GeneralHealth', 'MENTHLTH':'MentalHealth', 'PHYSHLTH':'PhysicalHealth', 'DIFFWALK':'DifficultyWalking', \n",
    "                                         'SEXVAR':'Sex', '_AGEG5YR':'AgeCategory', '_EDUCAG':'EducationLevel', 'INCOME3':'Income'})\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b485fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252888, 17)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bc3487fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes\n",
       "0.0    211801\n",
       "1.0      5893\n",
       "2.0     35194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.groupby(['Diabetes']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67b6c2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "888"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.to_sql('binary_diabetes_dataset', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aaf2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
